{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeece13c-fa83-4726-801d-c5af86963668",
   "metadata": {},
   "outputs": [],
   "source": [
    "What does the dataset represent? List all the transactions clearly.\n",
    "The dataset represents a list of transactions, where each transaction is a list of items purchased together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e1b57a-4c1c-41eb-a097-edf6b119fec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions:\n",
      "Transaction 1: ['Coffee', 'Donut', 'Sandwich']\n",
      "Transaction 2: ['Coffee', 'Donut']\n",
      "Transaction 3: ['Coffee', 'Sandwich']\n",
      "Transaction 4: ['Coffee', 'Muffin']\n",
      "Transaction 5: ['Donut', 'Muffin']\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "    ['Coffee', 'Donut', 'Sandwich'],\n",
    "    ['Coffee', 'Donut'],\n",
    "    ['Coffee', 'Sandwich'],\n",
    "    ['Coffee', 'Muffin'],\n",
    "    ['Donut', 'Muffin']\n",
    "]\n",
    "\n",
    "print(\"Transactions:\")\n",
    "for i, transaction in enumerate(dataset):\n",
    "    print(f\"Transaction {i+1}: {transaction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "370f4b68-be4c-42da-9c44-9d0f787c322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Coffee  Donut  Muffin  Sandwich\n",
      "0       1      1       0         1\n",
      "1       1      1       0         0\n",
      "2       1      0       0         1\n",
      "3       1      0       1         0\n",
      "4       0      1       1         0\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset into a one-hot encoded DataFrame.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Get unique items\n",
    "items = set()\n",
    "for transaction in dataset:\n",
    "    items.update(transaction)\n",
    "items = sorted(list(items))\n",
    "\n",
    "# One-hot encode transactions\n",
    "encoded_data = []\n",
    "for transaction in dataset:\n",
    "    encoded_transaction = [1 if item in transaction else 0 for item in items]\n",
    "    encoded_data.append(encoded_transaction)\n",
    "\n",
    "df = pd.DataFrame(encoded_data, columns=items)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25bb4657-d5c5-4091-8b27-97f39c0dccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   support            itemsets\n",
      "0      0.8            (Coffee)\n",
      "1      0.6             (Donut)\n",
      "2      0.4            (Muffin)\n",
      "3      0.4          (Sandwich)\n",
      "4      0.4     (Coffee, Donut)\n",
      "5      0.4  (Coffee, Sandwich)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gouth\\anaconda3\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#With minimum support = 0.4, identify all frequent itemsets.\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "frequent_itemsets = apriori(df, min_support=0.4, use_colnames=True)\n",
    "print(frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847a02e3-7a02-4342-ad1e-ce2dbe28787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0    (Coffee)     (Donut)                 0.8                 0.6      0.4   \n",
      "1     (Donut)    (Coffee)                 0.6                 0.8      0.4   \n",
      "2    (Coffee)  (Sandwich)                 0.8                 0.4      0.4   \n",
      "3  (Sandwich)    (Coffee)                 0.4                 0.8      0.4   \n",
      "\n",
      "   confidence      lift  representativity  leverage  conviction  \\\n",
      "0    0.500000  0.833333               1.0     -0.08         0.8   \n",
      "1    0.666667  0.833333               1.0     -0.08         0.6   \n",
      "2    0.500000  1.250000               1.0      0.08         1.2   \n",
      "3    1.000000  1.250000               1.0      0.08         inf   \n",
      "\n",
      "   zhangs_metric  jaccard  certainty  kulczynski  \n",
      "0      -0.500000      0.4  -0.250000    0.583333  \n",
      "1      -0.333333      0.4  -0.666667    0.583333  \n",
      "2       1.000000      0.5   0.166667    0.750000  \n",
      "3       0.333333      0.5   1.000000    0.750000  \n"
     ]
    }
   ],
   "source": [
    "#Generate all possible association rules.\n",
    "\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dfbe406-fdce-4237-b5aa-238f1028ab6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  antecedents consequents  antecedent support  consequent support  support  \\\n",
      "1     (Donut)    (Coffee)                 0.6                 0.8      0.4   \n",
      "3  (Sandwich)    (Coffee)                 0.4                 0.8      0.4   \n",
      "\n",
      "   confidence      lift  representativity  leverage  conviction  \\\n",
      "1    0.666667  0.833333               1.0     -0.08         0.6   \n",
      "3    1.000000  1.250000               1.0      0.08         inf   \n",
      "\n",
      "   zhangs_metric  jaccard  certainty  kulczynski  \n",
      "1      -0.333333      0.4  -0.666667    0.583333  \n",
      "3       0.333333      0.5   1.000000    0.750000  \n"
     ]
    }
   ],
   "source": [
    "# Which rules satisfy both minimum support (0.4) and minimum confidence (0.6)?\n",
    "\n",
    "rules_filtered = rules[(rules['support'] >= 0.4) & (rules['confidence'] >= 0.6)]\n",
    "print(rules_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a2a8f8b-b9eb-44e3-8a2a-72bb342eea79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If a customer buys frozenset({'Donut'}), they are likely to buy frozenset({'Coffee'}).\n"
     ]
    }
   ],
   "source": [
    " #Interpret one strong rule in words.\n",
    "#Let's take a rule from the filtered rules:\n",
    "\n",
    "\n",
    "if rules_filtered.shape[0] > 0:\n",
    "    rule = rules_filtered.iloc[0]\n",
    "    print(f\"If a customer buys {rule['antecedents']}, they are likely to buy {rule['consequents']}.\")\n",
    "else:\n",
    "    print(\"No rules satisfy the conditions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ff796-e8cf-40ad-a940-b39c48328267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
